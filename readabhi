Step by step walkthrough for creating a basic template
This tutorial will show you how to create template layout files using a simple example.

First let's make a layout for a sample OMR from Adrian's blog.
https://pyimagesearch.com/2016/10/03/bubble-sheet-multiple-choice-scanner-and-test-grader-using-omr-python-and-opencv/

![alt text](image-1.png)

1. Create a directory for your files, say `inputs/AdrianSamples`. Note that all directories in `inputs/` directory will be processed by default.

2. Download above OMR image and put it into `inputs/AdrianSamples/`.

3. Create a file inputs/template.json. Putting the following starter json in it.

```
{
  "pageDimensions": [ 300, 400 ],
  "bubbleDimensions": [ 20, 20 ],
  "customLabels": {},
  "fieldBlocks": {
    "MCQBlock1": {
      "fieldType": "QTYPE_MCQ5",
      "origin": [ 0, 0 ],
      "fieldLabels": ["q1", "q2", "q3", "q4", "q5"],
      "bubblesGap": 30,
      "labelsGap": 30
    }
  },
  "preProcessors": [
    {
      "name": "CropPage",
      "options": {
        "morphKernel": [ 10, 10 ]
      }
    }
  ]
}
```

Now run `*python3 main.py --setLayout*`. The page should get cropped automatically and show a basic overlay of the template. Note that we have put `"origin": [0, 0],` which means the overlay will start from the top left corner.

![alt text](image.png)

Now let's adjust the top left corner(origin). Change origin from `[0,0]` to a better coordinate, say `[50, 50]` and run above command again. After multiple trials, you should find that origin is best fit at `[65, 60]`. Update the origin in json file :

```
origin": [65, 60],
```

Run the command again.

![alt text](image-2.png)

Now let's tweak over the two gaps bubblesGap and labelsGap. Clearly we need to update the gaps to be bigger. Also, horizontal gaps are smaller than vertical ones. Tweaked gaps come out to be-

    "bubblesGap" : 41,
    "labelsGap" : 52,

The bubbles also should be made slightly bigger
```
  "bubbleDimensions": [25, 25 ],
```
Run the command again to get the arranged layout.

![alt text](image-3.png)

## For more templates see sample folders



# Meaning of parameters used in the template.json file
Let's take an example of sample1 from the samples.

You may use below commands from project root to load the sample template.

`python3 main.py -i samples/sample1 --setLayout`
Which shows the template overlay like below -

![alt text](image-4.png)

```
{
  // The dimensions(width, height) to which the page will be resized to before applying template
  "pageDimensions": [
    1846,
    1500
  ],
  // The dimensions of the overlay bubble area
  "bubbleDimensions": [
    40,
    40
  ],
  // Custom configuration values to use in the template's directory
  "preProcessors": [
    {
      // Page boundary based cropping plugin
      "name": "CropPage",
      "options": {
        // size of the kernel to use for cropping (default for most cases)
        "morphKernel": [
          10,
          10
        ]
      }
    },
    {
      // Marker based cropping plugin
      "name": "CropOnMarkers",
      "options": {
        // path to marker file
        "relativePath": "omr_marker.jpg",
        // a factor by which marker shall be resized relative to input image 
        "sheetToMarkerWidthRatio": 17
      }
    }
  ],
  
// The customLabels contain fields that need to be joined together before generating the results sheet
  "customLabels": {
    // Here the "Roll" key corresponds to a single column in the results
    "Roll": [
      "Medium",
      "roll1",
      "roll2",
      "roll3",
      "roll4",
      "roll5",
      "roll6",
      "roll7",
      "roll8",
      "roll9"
    ],
    // customLabels can also be used for two-digit integer type questions.
    "q5": [
      "q5_1",
      "q5_2"
    ],
    // ...
  },
  // Each rectangular box you see in the template overlay image is an item in fieldBlocks 
  "fieldBlocks": {
    // ...

    // Create a block of MCQ type questions

    "MCQ_Block_Q1": {
      // Here, QTYPE_MCQ4 is a built-in field type with four values ["A", "B", "C", "D"]
      "fieldType": "QTYPE_MCQ4",
      // The ordered questions in this block (length of this array is the number of questions in this block)
      "fieldLabels": ["q1", "q2", "q3", "q4"],
      // The gaps between the bubbles
      "bubblesGap": 59,
      // The gaps between the labels i.e. the mcq questions
      "labelsGap": 50,
      // The starting point of the block (top left)
      "origin": [121, 860]
    },
    
    // This shows how integer type questions are created.
    "Int_Block_Q5": {
      // Here, QTYPE_INT is a built-in field type with vertical arrangement of 0-9 integers
      "fieldType": "QTYPE_INT",
      // These field labels will concatenated together as declared in customLabels earlier.
      "fieldLabels": ["q5_1", "q5_2"],
      // The gaps between the bubbles
      "bubblesGap": 46,
      // The gaps between the labels i.e. the two integer columns
      "labelsGap": 60,
      // The starting point of the block (top left)
      "origin": [903, 282]
    },

    // A custom field
    "Medium": {
      // The starting point of the block (top left)
      "origin": [
        170,
        282
      ],
      // The direction of the bubbles
      "direction": "vertical",
      // The gaps between the bubbles
      "bubblesGap": 41,
      // Custom values for the bubbles (length of this array is the number of bubbles per field)
      "bubbleValues": ["E", "H"],
      // The labels for fields in the block 
      "fieldLabels": ["Medium"],
      // Since we have only one label in this block, we set labelsGap as 0
      "labelsGap": 0,
    },

    // ... rest of the fieldBlocks
  },
  // All the columns in order(custom and non-custom) to be outputted in the results sheet
  "outputColumns": [
    "Roll",
    "q1",
    "q2",
    // ...
  ],
  // The value to be used in case of empty bubble detected
  "emptyValue": ""
}
```
Please check the `sample1/` folder to understand the use of omr_marker.jpg. If you can modify your OMR sheets with these markers, it will give you much higher accuracy when scanning using mobile camera. We enable the markers plugin using the following snippet.

```
{
  // ...
  "preProcessors": [
    // ...
    {
      "name": "CropOnMarkers",
      "options": {
        "relativePath": "omr_marker.jpg",
      }
    }
  ]
}
```


# The evaluation.json file
This documentation provides a clear overview of the `evaluation.json` structure and its components, enabling efficient customization and understanding of the evaluation process within OMRChecker. Adjustments and expansions to meet specific evaluation needs can be made based on these defined parameters and configurations.

Meaning of Parameters Used in the evaluation.json File
To understand the structure and usage of the evaluation.json file for custom evaluation processes, let's delve into its parameters and configurations. Below is an annotated explanation of each section:

Note: Add evaluation.json at the same folder level as your template.json

List of capabilities
multiple marking schemes including negative/fractional
colored outputs with printing score,
set-mapping of answer keys.


## Source Types and Answer Key Options

`source_type`: Specifies the type of source data being evaluated, in this case, it's "local". We also support csv and image_and_csv sources. Please refer to the samples folder for more examples.

`questions_in_order`: Defines the questions in a serial order in the evaluation.
answers_in_order: Defines the answers expected in a serial order for each question in the evaluation.

## Types of answer keys supported:

Standard answer type: allows single correct answers. They can have multiple characters(multi-marked) as well. Useful for any standard response e.g. 'A', '01', '99', 'AB', etc

Multiple correct answer type: covers multiple correct answers Useful for ambiguous/bonus questions e.g. ['A', 'B'], ['1', '01'], ['A', 'B', 'AB'], etc

Multiple correct weighted answer: covers multiple answers with custom scores Useful for partial marking e.g. [['A', 2], ['B', 0.5], ['AB', 2.5]], [['1', 0.5], ['01', 1]], etc.

```
{
  "source_type": "local",
  "options": {
    // The field names mentioned in 'questions_in_order' are picked up from the OMR response.
    "questions_in_order": [
      "q1..10", // A field string indicating questions 1 to 11 (for default section)
      "s2_q1..5", // Another field string indicating questions 1 to 5 from another section
    ],
    // Various answer formats for each question
    "answers_in_order": [
        "A", // q1: Single correct answer 'A'
        "B", // q2: Single correct answer 'B'
        "AB", // q3: Multicharacter answer 'AB' (both A & B should be marked)
        ["A", "B"], // q4: Multiple correct answers (either A or B is correct but not both)
        ["A", "B", "AB"], // q5: Multiple correct answers (either A or B or both AB is correct)
        ["A", "B", "C", "D"], // q6: Effective bonus marks using custom score (without using bonus section)
        [["A", 2], ["D", 1], ["AD", 3]], // q7: Multiple answers with custom score (Marks for AD = 2 + 1 = 3)
        [["C", 10], ["D", -1]], // q8: Multiple answers with custom negative score
        "D", // q9: Original answer 'D' (But score overridden by bonus marking scheme below)
        "C", // q10: Original answer 'C' (But score overridden by bonus marking scheme below)
    ]
    "marking_schemes":{
        // Default marking scheme (fallback)
        "DEFAULT": {
            "correct": "3", // Default marking for correct answers
            "incorrect": "0", // Default marking for incorrect answers
            "unmarked": "0" // Default marking for unmarked answers
        },
        // Custom section with a different marking scheme
        "SECTION_2":{
            // List of questions to apply the marking scheme on
            "questions":["s2_q1..5"],
            // Custom marking on the section questions
            "marking": {
                "correct": "4",
                "incorrect": "-1",
                "unmarked": "0"
            }
        },
        // Another section mentioning bonus questions(on attempt)
        "BONUS_MARKS_ON_ATTEMPT": {
            "questions": [
                "q9"
            ],
            // Custom marking on the section questions
            "marking": {
                "correct": "3",
                "incorrect": "3",
                "unmarked": "0"
            }
        },
        // Another section mentioning bonus questions(with/without attempt)
        "BONUS_MARKS_FOR_ALL": {
            "questions": [
                "q10"
            ],
            "marking": {
                "correct": "3",
                "incorrect": "3",
                "unmarked": "3"
            }
        },
    }
  },
```

## Symbols and Color Notations

When draw_question_verdicts is enabled, the output images will contain the answer key and corresponding question verdicts. Both the gray and colored images follow a set of notations to show the different types of answers supported. The diagram below(initial draft) explains the possible answer key cases covered in a single picture:

![alt text](image-5.png)

Note: As of now the output notations for keys using customLabels are yet to be supported and will not be shown visually, but used in the score calculation directly.

## Outputs Configuration
`should_explain_scoring`: Indicates whether to print a table explaining question-wise verdicts.

`draw_score`: Configuration for drawing the final score, including its position and size.

`draw_answers_summary`: Configuration for drawing the answers summary, including its position and size.

`draw_question_verdicts`: Configuration for drawing question verdicts, specifying colors and symbols for different verdict types.

`draw_detected_bubble_texts`: Configuration for drawing detected bubble texts, which is disabled in this example.

```
{
  "outputs_configuration": {
    "should_explain_scoring": true, // Whether to explain question-wise verdicts
    "draw_score": {
      "enabled": true, // Enable drawing the score
      "position": [600, 650], // Position of the score box
      "size": 1.5 // Font size of the score box
    },
    "draw_answers_summary": {
      "enabled": true, // Enable drawing answers summary
      "position": [300, 550], // Position of the answers summary box
      "size": 1.0 // Font size of the answers summary box
    },
    "draw_question_verdicts": {
      "enabled": true, // Enable drawing question verdicts

      // Colors for different verdicts
      "verdict_colors": {
        "correct": "lightgreen", // Color for correct answers
        "neutral": "#000000", // Color for neutral verdicts (delta == 0)
        "incorrect": "#ff0000", // Color for incorrect answers
        "bonus": "#00DDDD" // Color for bonus questions
      },

      // Colors for different verdict symbols
      "verdict_symbol_colors": {
        "positive": "#000000", // Color for '+' symbol (delta > 0)
        "neutral": "#000000", // Color for 'o' symbol (delta == 0)
        "negative": "#000000", // Color for '-' symbol (delta < 0)
        "bonus": "#000000" // Color for '*' symbol (bonus question)
      },

      // Configuration for drawing answer groups
      "draw_answer_groups": {
        "enabled": true // Enable drawing answer groups
      }
    },
    "draw_detected_bubble_texts": {
      "enabled": false // Disable drawing detected bubble texts
    }
  },
}
```

Example Usage
To load and utilize this schema, navigate to the project root and execute the following command:

`python3 main.py -i samples/3-answer-key/bonus-marking-grouping`


# for config.json

```
{
    "title": "Config Schema",
    "description": "OMRChecker config schema for custom tuning",
    "thresholding": {
        "description": "The values used in the core algorithm of OMRChecker",
        "MIN_GAP_TWO_BUBBLES": {
            "description": "Minimum difference between all mean values of the bubbles. Used for local thresholding of 2 or 1 bubbles",
        },
        "MIN_JUMP": {
            "description": "Minimum difference between consecutive elements to be consider as a jump in a sorted array of mean values of the bubbles",
        },
        "MIN_JUMP_STD": {
            "description": "The MIN_JUMP for the standard deviation plot",
        },
        "MIN_JUMP_SURPLUS_FOR_GLOBAL_FALLBACK": {
            "description": "This value is added to jump value, underconfident bubbles fallback to global_threshold_for_template",
        },
        "GLOBAL_THRESHOLD_MARGIN": {
            "description": 'This value determines if the calculated global threshold is "too close" to lower bubbles in confidence metrics',
        },
        "JUMP_DELTA": {
            "description": "Note: JUMP_DELTA is deprecated, used only in plots currently to determine a stricter threshold",
        },
        "JUMP_DELTA_STD": {
            "description": "JUMP_DELTA_STD is the minimum delta to be considered as a jump in the std plot",
        },
        "CONFIDENT_JUMP_SURPLUS_FOR_DISPARITY": {
            "description": "This value is added to jump value to distinguish safe detections vs underconfident detections",
        },
        "GLOBAL_PAGE_THRESHOLD": {
            "description": "This option decides the starting value to use before applying local outlier threshold",
        },
        "GLOBAL_PAGE_THRESHOLD_STD": {
            "description": "This option decides the starting value to use for standard deviation threshold which determines outliers",
        },
        "GAMMA_LOW": {
            "description": "Used in the CropOnDotLines processor to create a darker image for enhanced line detection (darker boxes)",
        },
    },
    "outputs": {
        "description": "The configuration related to the outputs generated by OMRChecker",

        "display_image_dimensions": {
            "description": "The dimensions (width, height) for images displayed during the execution",
        },
        "show_logs_by_type": {
            "description": "The toggles for enabling logs per level",
            "properties": {
                "critical": true,
                "error": true,
                "warning": true,
                "info": true,
                "debug": true,
            },
        },
        "show_image_level": {
            "description": "The toggle level for showing debug images (higher means more debug images)",
        },
        "save_image_level": {
            "description": "The toggle level for saving debug images (higher means more debug images)",
        },
        "colored_outputs_enabled": {
            "description": "This option shows colored outputs while taking a small toll on the processing speeds. Disable this option to slightly improve the speed",
        },
        "save_detections": {
            "description": "This option saves the detection outputs while taking a small toll on the processing speeds",
        },
        "save_image_metrics": {
            "description": "This option exports the confidence metrics etc related to the images. These can be later used for deeper analysis/visualizations",
        },
        "filter_out_multimarked_files": {
            "description": "This option moves files having multi-marked responses into a separate folder for manual checking, skipping evaluation",
        },
        "show_preprocessors_diff": {
            "description": "This option shows a preview of the processed image for every preprocessor. Also granular at preprocessor level using a map",
            "properties": {
                "CropOnMarkers": true,
                "CropPage": true,
                "FeatureBasedAlignment": true,
                "GaussianBlur": true,
                "Levels": true,
                "MedianBlur": true,
                "AutoAlign": true,
            },
        },
    },
}
```
