# import cv2
# import matplotlib.pyplot as plt
# from scipy import ndimage
# from time import time
# from datetime import datetime
# from skimage.io import imread
# from keras.models import load_model



inference_set = ['../Dataset/prints_to_test_25/',]

CoarseNet_path = '../Models/CoarseNet.h5'

output_dir = '../output_CoarseNet_25/'+datetime.now().strftime('%Y%m%d-%H%M%S')

FineNet_path = '../Models/FineNet.h5'

logging = init_log(output_dir)

# If use FineNet to refine, set into True
isHavingFineNet = False

for i, deploy_set in enumerate(inference_set):
    set_name = deploy_set.split('/')[-2]

    # Read image and GT
    img_name, folder_name, img_size = get_maximum_img_size_and_names(deploy_set)

    mkdir(output_dir + '/'+ set_name + '/')
    mkdir(output_dir + '/' + set_name + '/mnt_results/')
    mkdir(output_dir + '/'+ set_name + '/seg_results/')
    mkdir(output_dir + '/' + set_name + '/OF_results/')
    mkdir(output_dir + '/' + set_name + '/enhance_img_results/')

    logging.info("Predicting \"%s\":" % (set_name))

    main_net_model = CoarseNetmodel((None, None, 1), CoarseNet_path, mode='deploy')

    # ====== Load FineNet to verify
    if isHavingFineNet == True:
        model_FineNet = FineNetmodel(num_classes=2,
                             pretrained_path=FineNet_path,
                             input_shape=(224,224,3))

        model_FineNet.compile(loss='categorical_crossentropy',
                      optimizer=Adam(lr=0),
                      metrics=['accuracy'])

    for i in range(0, len(img_name)):
        
        logging.info("\"%s\" %d / %d: %s" % (set_name, i + 1, len(img_name), img_name[i]))

        image = imread(deploy_set + 'img_files/' + img_name[i] + '.bmp', mode='L')  # / 255.0

        img_size = image.shape
        img_size = np.array(img_size, dtype=np.int32) // 8 * 8
        image = image[:img_size[0], :img_size[1]]

        original_image = image.copy()

        # Generate OF
        texture_img = FastEnhanceTexture(image, sigma=2.5, show=False)
        dir_map, fre_map = get_maps_STFT(texture_img, patch_size=64, block_size=16, preprocess=True)
        
        image = np.reshape(image, [1, image.shape[0], image.shape[1], 1])

        enh_img, enh_img_imag, enhance_img, ori_out_1, ori_out_2, seg_out, mnt_o_out, mnt_w_out, mnt_h_out, mnt_s_out = \
            main_net_model.predict(image)

        # Check the shape and values of enhance_img for debugging
        print(f"Shape of enhance_img: {enhance_img.shape}")
        print(f"Min and Max values of enhance_img: {np.min(enhance_img)}, {np.max(enhance_img)}")

        # Normalize the enhance_img to proper image scale [0, 255]
        enhance_img = np.clip(enhance_img, 0, 1)  # Ensure values are in the range [0, 1]
        enhance_img = (enhance_img * 255).astype(np.uint8)  # Convert to 8-bit integers

        # Optionally, visualize the image for debugging
        # plt.imshow(enhance_img, cmap='gray')
        # plt.show()

        # Save the enhanced image
        plt.imsave(f"{output_dir}/{set_name}/enhance_img_results/{img_name[i]}_enhance_img.jpg", enhance_img, cmap='gray')

        # Use for output mask
        round_seg = np.round(np.squeeze(seg_out))
        seg_out = 1 - round_seg
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))
        seg_out = cv2.morphologyEx(seg_out, cv2.MORPH_CLOSE, kernel)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))
        seg_out = cv2.morphologyEx(seg_out, cv2.MORPH_OPEN, kernel)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        seg_out = cv2.dilate(seg_out, kernel)

        #========== Adaptive threshold ==================
        final_minutiae_score_threashold = 0.45
        early_minutiae_thres = final_minutiae_score_threashold + 0.05

        # In cases of small amount of minutiae given, try adaptive threshold
        while final_minutiae_score_threashold >= 0:
            mnt = label2mnt(np.squeeze(mnt_s_out) * np.round(np.squeeze(seg_out)), mnt_w_out, mnt_h_out, mnt_o_out,
                            thresh=early_minutiae_thres)

            mnt_nms_1 = py_cpu_nms(mnt, 0.5)
            mnt_nms_2 = nms(mnt)
            # Make sure good result is given
            if mnt_nms_1.shape[0] > 4 and mnt_nms_2.shape[0] > 4:
                break
            else:
                final_minutiae_score_threashold = final_minutiae_score_threashold - 0.05
                early_minutiae_thres = early_minutiae_thres - 0.05

        mnt_nms = fuse_nms(mnt_nms_1, mnt_nms_2)

        mnt_nms = mnt_nms[mnt_nms[:, 3] > early_minutiae_thres, :]
        mnt_refined = []

        if isHavingFineNet == True:
            # ======= Verify using FineNet ============
            patch_minu_radio = 22
            if FineNet_path != None:
                for idx_minu in range(mnt_nms.shape[0]):
                    try:
                        # Extract patch from image
                        x_begin = int(mnt_nms[idx_minu, 1]) - patch_minu_radio
                        y_begin = int(mnt_nms[idx_minu, 0]) - patch_minu_radio
                        patch_minu = original_image[x_begin:x_begin + 2 * patch_minu_radio,
                                     y_begin:y_begin + 2 * patch_minu_radio]

                        patch_minu = cv2.resize(patch_minu, dsize=(224, 224), interpolation=cv2.INTER_NEAREST)

                        ret = np.empty((patch_minu.shape[0], patch_minu.shape[1], 3), dtype=np.uint8)
                        ret[:, :, 0] = patch_minu
                        ret[:, :, 1] = patch_minu
                        ret[:, :, 2] = patch_minu
                        patch_minu = ret
                        patch_minu = np.expand_dims(patch_minu, axis=0)

                        # Use soft decision: merge FineNet score with CoarseNet score
                        [isMinutiaeProb] = model_FineNet.predict(patch_minu)
                        isMinutiaeProb = isMinutiaeProb[0]
                        tmp_mnt = mnt_nms[idx_minu, :].copy()
                        tmp_mnt[3] = (4 * tmp_mnt[3] + isMinutiaeProb) / 5
                        mnt_refined.append(tmp_mnt)

                    except:
                        mnt_refined.append(mnt_nms[idx_minu, :])
        else:
            mnt_refined = mnt_nms

        mnt_nms_backup = mnt_nms.copy()
        mnt_nms = np.array(mnt_refined)

        if mnt_nms.shape[0] > 0:
            mnt_nms = mnt_nms[mnt_nms[:, 3] > final_minutiae_score_threashold, :]

        final_mask = ndimage.zoom(np.round(np.squeeze(seg_out)), [8, 8], order=0)
        # Show the orientation
        show_orientation_field(original_image, dir_map + np.pi, mask=final_mask, fname="%s/%s/OF_results/%s_OF.jpg" % (output_dir, set_name, img_name[i]))

        fuse_minu_orientation(dir_map, mnt_nms, mode=3)

        time_afterpost = time()
        mnt_writer(mnt_nms, img_name[i], img_size, "%s/%s/mnt_results/%s.mnt" % (output_dir, set_name, img_name[i]))
        draw_minutiae(original_image, mnt_nms, "%s/%s/%s_minu.jpg" % (output_dir, set_name, img_name[i]), saveimage=True)

        plt.imsave("%s/%s/seg_results/%s_seg.jpg" % (output_dir, set_name, img_name[i]), final_mask, cmap='gray')
ChatGPT said:
ChatGPT
It seems like you're having trouble displaying or saving the enhance_img correctly despite it having a shape of [1, 512, 512, 1], which indicates it's a 4D tensor (batch size, height, width, channels). Here are some potential reasons and fixes for the issue where enhance_img appears blank:

1. Reshape and Squeeze the Image:
The enhance_img is likely in the shape [1, 512, 512, 1], so it needs to be squeezed or reshaped into a 2D image (height, width) for proper visualization and saving.

Solution: Before saving or displaying the image, you can squeeze the unnecessary dimensions:

python
Copy code
enhance_img = np.squeeze(enhance_img)  # Remove the singleton dimensions (batch and channel)
Now, the shape of enhance_img should be [512, 512], which is suitable for saving with plt.imsave().

2. Ensure Image Values Are in the Range [0, 255]:
Sometimes, if the image's values are not correctly scaled to the range [0, 255], it can appear blank or very dark. In your code, you already attempt to scale it using np.clip and multiply by 255, but double-check the values before saving.

Solution:

python
Copy code
enhance_img = np.squeeze(enhance_img)  # Remove singleton dimensions
enhance_img = np.clip(enhance_img, 0, 1)  # Ensure values are between [0, 1]
enhance_img = (enhance_img * 255).astype(np.uint8)  # Convert to [0, 255] range and uint8 format
3. Check if the Enhance Image Is Empty:
If enhance_img is filled with zeros or extremely small values, the saved image will appear blank. Print out some statistics about the image to verify this.

Solution:

python
Copy code
print(f"Min value: {np.min(enhance_img)}, Max value: {np.max(enhance_img)}")
if np.min(enhance_img) == 0 and np.max(enhance_img) == 0:
    print("Warning: enhance_img contains only zeros!")
4. Ensure the Directory for Saving the Image Exists:
Double-check that the target directory for saving the image exists. If not, the saving process will fail silently.

Solution:

python
Copy code
output_dir_enhance = f"{output_dir}/{set_name}/enhance_img_results/"
os.makedirs(output_dir_enhance, exist_ok=True)  # Ensure the directory exists
Full Example of Saving the Enhanced Image:
python
Copy code
# Assuming enhance_img is already predicted and has shape [1, 512, 512, 1]
enhance_img = np.squeeze(enhance_img)  # Remove singleton dimensions
enhance_img = np.clip(enhance_img, 0, 1)  # Ensure values are between [0, 1]
enhance_img = (enhance_img * 255).astype(np.uint8)  # Convert to [0, 255] range and uint8 format

# Check if the image has valid values
print(f"Min value: {np.min(enhance_img)}, Max value: {np.max(enhance_img)}")

# Ensure the output directory exists
output_dir_enhance = f"{output_dir}/{set_name}/enhance_img_results/"
os.makedirs(output_dir_enhance, exist_ok=True)

# Save the enhanced image
output_path = f"{output_dir_enhance}/{img_name[i]}_enhance_img.jpg"
plt.imsave(output_path, enhance_img, cmap='gray')
print(f"Enhanced image saved at {output_path}")
Summary of Key Fixes:
Reshape the image to remove unnecessary dimensions (np.squeeze(enhance_img)).
Scale the image to the [0, 255] range if needed ((enhance_img * 255).astype(np.uint8)).
Check values of enhance_img before saving to ensure it's not all zeros.
Ensure directory for saving images exists (os.makedirs(output_dir_enhance, exist_ok=True)).
Try these fixes and let me know if the issue persists!


You said:
please giev the entire code , i just wanted to copy and paste :
ChatGPT said:
ChatGPT
Here is the entire code with the modifications to ensure that the enhance_img is properly processed and saved without being blank.

python
Copy code
import numpy as np
import cv2
import matplotlib.pyplot as plt
from scipy import ndimage
from time import time
from datetime import datetime
from skimage.io import imread
from keras.models import load_model
import os

# Define utility functions (add these if you have them)

def mkdir(path):
    if not os.path.exists(path):
        os.makedirs(path)

def init_log(output_dir):
    # Implement logging initialization here
    pass

def get_maximum_img_size_and_names(deploy_set):
    # Implement your image size and name retrieval logic
    return img_name, folder_name, img_size

def FastEnhanceTexture(image, sigma=2.5, show=False):
    # Your texture enhancement function
    return texture_img

def get_maps_STFT(texture_img, patch_size=64, block_size=16, preprocess=True):
    # Your function to get the maps
    return dir_map, fre_map

def CoarseNetmodel(input_shape, model_path, mode='deploy'):
    # Your CoarseNet model loading function
    return model

def FineNetmodel(num_classes, pretrained_path, input_shape):
    # Your FineNet model loading function
    return model

def py_cpu_nms(mnt, threshold):
    # Your NMS function
    return mnt_nms

def nms(mnt):
    # Your NMS function
    return mnt_nms

def fuse_nms(mnt_nms_1, mnt_nms_2):
    # Your fusion function
    return mnt_nms

def label2mnt(mnt_s_out, mnt_w_out, mnt_h_out, mnt_o_out, thresh):
    # Your minutiae extraction function
    return mnt

def show_orientation_field(original_image, dir_map, mask, fname):
    # Your orientation field visualization function
    pass

def draw_minutiae(original_image, mnt_nms, fname, saveimage=True):
    # Your minutiae drawing function
    pass

def mnt_writer(mnt_nms, img_name, img_size, output_path):
    # Your minutiae writing function
    pass

# Main function
inference_set = ['../Dataset/prints_to_test_25/',]
CoarseNet_path = '../Models/CoarseNet.h5'
output_dir = '../output_CoarseNet_25/'+datetime.now().strftime('%Y%m%d-%H%M%S')
FineNet_path = '../Models/FineNet.h5'
logging = init_log(output_dir)

# If use FineNet to refine, set into True
isHavingFineNet = False

for i, deploy_set in enumerate(inference_set):
    set_name = deploy_set.split('/')[-2]

    # Read image and GT
    img_name, folder_name, img_size = get_maximum_img_size_and_names(deploy_set)

    mkdir(output_dir + '/'+ set_name + '/')
    mkdir(output_dir + '/' + set_name + '/mnt_results/')
    mkdir(output_dir + '/'+ set_name + '/seg_results/')
    mkdir(output_dir + '/' + set_name + '/OF_results/')
    mkdir(output_dir + '/' + set_name + '/enhance_img_results/')

    logging.info("Predicting \"%s\":" % (set_name))

    main_net_model = CoarseNetmodel((None, None, 1), CoarseNet_path, mode='deploy')

    if isHavingFineNet == True:
        model_FineNet = FineNetmodel(num_classes=2,
                             pretrained_path=FineNet_path,
                             input_shape=(224,224,3))
        model_FineNet.compile(loss='categorical_crossentropy',
                      optimizer='adam',
                      metrics=['accuracy'])

    for i in range(0, len(img_name)):
        
        logging.info("\"%s\" %d / %d: %s" % (set_name, i + 1, len(img_name), img_name[i]))

        image = imread(deploy_set + 'img_files/' + img_name[i] + '.bmp', mode='L')  # / 255.0
        img_size = np.array(image.shape, dtype=np.int32) // 8 * 8
        image = image[:img_size[0], :img_size[1]]
        original_image = image.copy()

        # Generate OF
        texture_img = FastEnhanceTexture(image, sigma=2.5, show=False)
        dir_map, fre_map = get_maps_STFT(texture_img, patch_size=64, block_size=16, preprocess=True)
        
        image = np.reshape(image, [1, image.shape[0], image.shape[1], 1])

        enh_img, enh_img_imag, enhance_img, ori_out_1, ori_out_2, seg_out, mnt_o_out, mnt_w_out, mnt_h_out, mnt_s_out = \
            main_net_model.predict(image)

        # Check the shape and values of enhance_img for debugging
        print(f"Shape of enhance_img: {enhance_img.shape}")
        print(f"Min and Max values of enhance_img: {np.min(enhance_img)}, {np.max(enhance_img)}")

        # Normalize the enhance_img to proper image scale [0, 255]
        enhance_img = np.squeeze(enhance_img)  # Remove singleton dimensions
        enhance_img = np.clip(enhance_img, 0, 1)  # Ensure values are in the range [0, 1]
        enhance_img = (enhance_img * 255).astype(np.uint8)  # Convert to 8-bit integers

        # Check if the image has valid values
        print(f"Min value: {np.min(enhance_img)}, Max value: {np.max(enhance_img)}")
        if np.min(enhance_img) == 0 and np.max(enhance_img) == 0:
            print("Warning: enhance_img contains only zeros!")

        # Ensure the output directory exists
        output_dir_enhance = f"{output_dir}/{set_name}/enhance_img_results/"
        os.makedirs(output_dir_enhance, exist_ok=True)

        # Save the enhanced image
        output_path = f"{output_dir_enhance}/{img_name[i]}_enhance_img.jpg"
        plt.imsave(output_path, enhance_img, cmap='gray')
        print(f"Enhanced image saved at {output_path}")

        # Use for output mask
        round_seg = np.round(np.squeeze(seg_out))
        seg_out = 1 - round_seg
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))
        seg_out = cv2.morphologyEx(seg_out, cv2.MORPH_CLOSE, kernel)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))
        seg_out = cv2.morphologyEx(seg_out, cv2.MORPH_OPEN, kernel)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        seg_out = cv2.dilate(seg_out, kernel)

        # Adaptive threshold
        final_minutiae_score_threashold = 0.45
        early_minutiae_thres = final_minutiae_score_threashold + 0.05

        while final_minutiae_score_threashold >= 0:
            mnt = label2mnt(np.squeeze(mnt_s_out) * np.round(np.squeeze(seg_out)), mnt_w_out, mnt_h_out, mnt_o_out,
                            thresh=early_minutiae_thres)
            mnt_nms_1 = py_cpu_nms(mnt, 0.5)
            mnt_nms_2 = nms(mnt)
            if mnt_nms_1.shape[0] > 4 and mnt_nms_2.shape[0] > 4:
                break
            else:
                final_minutiae_score_threashold = final_minutiae_score_threashold - 0.05
                early_minutiae_thres = early_minutiae_thres - 0.05

        mnt_nms = fuse_nms(mnt_nms_1, mnt_nms_2)
        mnt_nms = mnt_nms[mnt_nms[:, 3] > early_minutiae_thres, :]
        mnt_refined = []

        if isHavingFineNet == True:
            patch_minu_radio = 22
            for idx_minu in range(mnt_nms.shape[0]):
                try:
                    x_begin = int(mnt_nms[idx_minu, 1]) - patch_minu_radio
                    y_begin = int(mnt_nms[idx_minu, 0]) - patch_minu_radio
                    patch_minu = original_image[x_begin:x_begin + 2 * patch_minu_radio,
                                 y_begin:y_begin + 2 * patch_minu_radio]
                    patch_minu = cv2.resize(patch_minu, dsize=(224, 224), interpolation=cv2.INTER_NEAREST)
                    ret = np.empty((patch_minu.shape[0], patch_minu.shape[1], 3), dtype=np.uint8)
                    ret[:, :, 0] = patch_minu
                    ret[:, :, 1] = patch_minu
                    ret[:, :, 2] = patch_minu
                    patch_minu = np.expand_dims(patch_minu, axis=0)
                    [isMinutiaeProb] = model_FineNet.predict(patch_minu)
                    isMinutiaeProb =

You said:
please generate code in this style:# import numpy as np
# import cv2
# import matplotlib.pyplot as plt
# from scipy import ndimage
# from time import time
# from datetime import datetime
# from skimage.io import imread
# from keras.models import load_model



inference_set = ['../Dataset/prints_to_test_25/',]

CoarseNet_path = '../Models/CoarseNet.h5'

output_dir = '../output_CoarseNet_25/'+datetime.now().strftime('%Y%m%d-%H%M%S')

FineNet_path = '../Models/FineNet.h5'

logging = init_log(output_dir)

# If use FineNet to refine, set into True
isHavingFineNet = False

for i, deploy_set in enumerate(inference_set):
    set_name = deploy_set.split('/')[-2]

    # Read image and GT
    img_name, folder_name, img_size = get_maximum_img_size_and_names(deploy_set)

    mkdir(output_dir + '/'+ set_name + '/')
    mkdir(output_dir + '/' + set_name + '/mnt_results/')
    mkdir(output_dir + '/'+ set_name + '/seg_results/')
    mkdir(output_dir + '/' + set_name + '/OF_results/')
    mkdir(output_dir + '/' + set_name + '/enhance_img_results/')

    logging.info("Predicting \"%s\":" % (set_name))

    main_net_model = CoarseNetmodel((None, None, 1), CoarseNet_path, mode='deploy')

    # ====== Load FineNet to verify
    if isHavingFineNet == True:
        model_FineNet = FineNetmodel(num_classes=2,
                             pretrained_path=FineNet_path,
                             input_shape=(224,224,3))

        model_FineNet.compile(loss='categorical_crossentropy',
                      optimizer=Adam(lr=0),
                      metrics=['accuracy'])

    for i in range(0, len(img_name)):
        
        logging.info("\"%s\" %d / %d: %s" % (set_name, i + 1, len(img_name), img_name[i]))

        image = imread(deploy_set + 'img_files/' + img_name[i] + '.bmp', mode='L')  # / 255.0

        img_size = image.shape
        img_size = np.array(img_size, dtype=np.int32) // 8 * 8
        image = image[:img_size[0], :img_size[1]]

        original_image = image.copy()

        # Generate OF
        texture_img = FastEnhanceTexture(image, sigma=2.5, show=False)
        dir_map, fre_map = get_maps_STFT(texture_img, patch_size=64, block_size=16, preprocess=True)
        
        image = np.reshape(image, [1, image.shape[0], image.shape[1], 1])

        enh_img, enh_img_imag, enhance_img, ori_out_1, ori_out_2, seg_out, mnt_o_out, mnt_w_out, mnt_h_out, mnt_s_out = \
            main_net_model.predict(image)

        # Check the shape and values of enhance_img for debugging
        print(f"Shape of enhance_img: {enhance_img.shape}")
        print(f"Min and Max values of enhance_img: {np.min(enhance_img)}, {np.max(enhance_img)}")

        # Normalize the enhance_img to proper image scale [0, 255]
        enhance_img = np.clip(enhance_img, 0, 1)  # Ensure values are in the range [0, 1]
        enhance_img = (enhance_img * 255).astype(np.uint8)  # Convert to 8-bit integers

        # Optionally, visualize the image for debugging
        # plt.imshow(enhance_img, cmap='gray')
        # plt.show()

        # Save the enhanced image
        plt.imsave(f"{output_dir}/{set_name}/enhance_img_results/{img_name[i]}_enhance_img.jpg", enhance_img, cmap='gray')

        # Use for output mask
        round_seg = np.round(np.squeeze(seg_out))
        seg_out = 1 - round_seg
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))
        seg_out = cv2.morphologyEx(seg_out, cv2.MORPH_CLOSE, kernel)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))
        seg_out = cv2.morphologyEx(seg_out, cv2.MORPH_OPEN, kernel)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        seg_out = cv2.dilate(seg_out, kernel)

        #========== Adaptive threshold ==================
        final_minutiae_score_threashold = 0.45
        early_minutiae_thres = final_minutiae_score_threashold + 0.05

        # In cases of small amount of minutiae given, try adaptive threshold
        while final_minutiae_score_threashold >= 0:
            mnt = label2mnt(np.squeeze(mnt_s_out) * np.round(np.squeeze(seg_out)), mnt_w_out, mnt_h_out, mnt_o_out,
                            thresh=early_minutiae_thres)

            mnt_nms_1 = py_cpu_nms(mnt, 0.5)
            mnt_nms_2 = nms(mnt)
            # Make sure good result is given
            if mnt_nms_1.shape[0] > 4 and mnt_nms_2.shape[0] > 4:
                break
            else:
                final_minutiae_score_threashold = final_minutiae_score_threashold - 0.05
                early_minutiae_thres = early_minutiae_thres - 0.05

        mnt_nms = fuse_nms(mnt_nms_1, mnt_nms_2)

        mnt_nms = mnt_nms[mnt_nms[:, 3] > early_minutiae_thres, :]
        mnt_refined = []

        if isHavingFineNet == True:
            # ======= Verify using FineNet ============
            patch_minu_radio = 22
            if FineNet_path != None:
                for idx_minu in range(mnt_nms.shape[0]):
                    try:
                        # Extract patch from image
                        x_begin = int(mnt_nms[idx_minu, 1]) - patch_minu_radio
                        y_begin = int(mnt_nms[idx_minu, 0]) - patch_minu_radio
                        patch_minu = original_image[x_begin:x_begin + 2 * patch_minu_radio,
                                     y_begin:y_begin + 2 * patch_minu_radio]

                        patch_minu = cv2.resize(patch_minu, dsize=(224, 224), interpolation=cv2.INTER_NEAREST)

                        ret = np.empty((patch_minu.shape[0], patch_minu.shape[1], 3), dtype=np.uint8)
                        ret[:, :, 0] = patch_minu
                        ret[:, :, 1] = patch_minu
                        ret[:, :, 2] = patch_minu
                        patch_minu = ret
                        patch_minu = np.expand_dims(patch_minu, axis=0)

                        # Use soft decision: merge FineNet score with CoarseNet score
                        [isMinutiaeProb] = model_FineNet.predict(patch_minu)
                        isMinutiaeProb = isMinutiaeProb[0]
                        tmp_mnt = mnt_nms[idx_minu, :].copy()
                        tmp_mnt[3] = (4 * tmp_mnt[3] + isMinutiaeProb) / 5
                        mnt_refined.append(tmp_mnt)

                    except:
                        mnt_refined.append(mnt_nms[idx_minu, :])
        else:
            mnt_refined = mnt_nms

        mnt_nms_backup = mnt_nms.copy()
        mnt_nms = np.array(mnt_refined)

        if mnt_nms.shape[0] > 0:
            mnt_nms = mnt_nms[mnt_nms[:, 3] > final_minutiae_score_threashold, :]

        final_mask = ndimage.zoom(np.round(np.squeeze(seg_out)), [8, 8], order=0)
        # Show the orientation
        show_orientation_field(original_image, dir_map + np.pi, mask=final_mask, fname="%s/%s/OF_results/%s_OF.jpg" % (output_dir, set_name, img_name[i]))

        fuse_minu_orientation(dir_map, mnt_nms, mode=3)

        time_afterpost = time()
        mnt_writer(mnt_nms, img_name[i], img_size, "%s/%s/mnt_results/%s.mnt" % (output_dir, set_name, img_name[i]))
        draw_minutiae(original_image, mnt_nms, "%s/%s/%s_minu.jpg" % (output_dir, set_name, img_name[i]), saveimage=True)

        plt.imsave("%s/%s/seg_results/%s_seg.jpg" % (output_dir, set_name, img_name[i]), final_mask, cmap='gray')
